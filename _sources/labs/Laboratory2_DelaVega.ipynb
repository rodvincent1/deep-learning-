{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c7cda830",
      "metadata": {
        "id": "c7cda830"
      },
      "source": [
        "\n",
        "# Laboratory 2  \n",
        "**Name:** Rod Vincent Dela Vega\n",
        "\n",
        "**Section:** DS4A\n",
        "\n",
        "**Task:** Perform a single forward pass and compute for the error.\n",
        "\n",
        "---\n",
        "\n",
        "### **Objective**\n",
        "To perform a single forward pass in a simple neural network and compute for the resulting error.\n",
        "\n",
        "### **Given Data**\n",
        "We are given:\n",
        "\n",
        "\\[\n",
        "x =\n",
        "\\begin{bmatrix}\n",
        "1 \\\\\n",
        "0 \\\\\n",
        "1\n",
        "\\end{bmatrix},\n",
        "\\quad\n",
        "y = [1],\n",
        "\\quad\n",
        "f = \\max(0, Z_n)\n",
        "\\]\n",
        "\n",
        "**Hidden Unit Weights:**  \n",
        "\\[\n",
        "\\begin{bmatrix}\n",
        "w_{11}=0.2 & w_{12}=-0.3 \\\\\n",
        "w_{13}=0.4 & w_{14}=0.1 \\\\\n",
        "w_{15}=-0.5 & w_{16}=0.2\n",
        "\\end{bmatrix}\n",
        "\\]\n",
        "\n",
        "**Output Unit Weights:**  \n",
        "\\[\n",
        "w_{21}=-0.3, \\quad w_{22}=-0.2\n",
        "\\]\n",
        "\n",
        "**Bias (θ):**  \n",
        "\\[\n",
        "\\theta_1=-0.4, \\quad \\theta_2=0.2, \\quad \\theta_3=0.1\n",
        "\\]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ad91fdab",
      "metadata": {
        "id": "ad91fdab"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# Input and target output\n",
        "x = np.array([[1], [0], [1]])\n",
        "y = np.array([[1]])\n",
        "\n",
        "# Hidden layer weights (3x2)\n",
        "W1 = np.array([[0.2, -0.3],\n",
        "               [0.4,  0.1],\n",
        "               [-0.5,  0.2]])\n",
        "\n",
        "# Output layer weights (1x2)\n",
        "W2 = np.array([[-0.3, -0.2]])\n",
        "\n",
        "# Biases\n",
        "theta = np.array([[-0.4], [0.2], [0.1]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4b034a69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b034a69",
        "outputId": "07251e47-66fd-49ad-db9c-bf5417580088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden Layer Input (Z):\n",
            " [[-0.7]\n",
            " [ 0.1]]\n",
            "\n",
            "Activated Output (f):\n",
            " [[0. ]\n",
            " [0.1]]\n",
            "\n",
            "Predicted Output (y_hat):\n",
            " [[-0.02]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Compute the hidden layer input Z = W1^T * x + theta\n",
        "Z = np.dot(W1.T, x) + theta[:2]  # We'll use the first two bias terms for hidden units\n",
        "\n",
        "# Apply ReLU activation function\n",
        "f = np.maximum(0, Z)\n",
        "\n",
        "# Compute the output\n",
        "y_hat = np.dot(W2, f)\n",
        "\n",
        "# Display intermediate results\n",
        "print(\"Hidden Layer Input (Z):\\n\", Z)\n",
        "print(\"\\nActivated Output (f):\\n\", f)\n",
        "print(\"\\nPredicted Output (y_hat):\\n\", y_hat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a9e45326",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9e45326",
        "outputId": "f563a6c9-4b5b-4616-9dd6-bbb20eb50ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error (E): 0.5202\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Compute error\n",
        "E = 0.5 * (y - y_hat)**2\n",
        "print(\"Error (E):\", E[0][0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aeac307",
      "metadata": {
        "id": "7aeac307"
      },
      "source": [
        "\n",
        "### **Result Summary**\n",
        "- **Hidden layer input (Z):** Computed using matrix multiplication and bias addition.  \n",
        "- **Activation output (f):** Obtained by applying the ReLU function.  \n",
        "- **Predicted output (ŷ):** Calculated using the output weights.  \n",
        "- **Error (E):** Computed using the formula \\( E = \\frac{1}{2}(y - \\hat{y})^2 \\).  \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}